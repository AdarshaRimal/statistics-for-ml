# Famous Probability Distributions
Before diving into the distributions, lets talk about mathematical expectation first.
## Mathematical Expectation

### 🌟 Why Do We Need Mathematical Expectation?

Imagine you're playing a game where you flip a coin:

- **If heads, you win ₹10.**
- **If tails, you lose ₹5.**

Would you play the game?  
To decide, you need a way to measure the average outcome if you played many times. This is where **expected value** comes in.  

🔁 *It helps us know the average outcome over the long run, even when results are random.*

### 💡 What Is Mathematical Expectation?

**Mathematical Expectation** (or **Expected Value**) is the **weighted average of all possible values** a random variable can take, weighted by their probabilities.

---

#### 🔢 For Discrete Random Variables

Let’s say a random variable \( X \) can take values \( x_1, x_2, ..., x_n \)  
with probabilities \( p_1, p_2, ..., p_n \).

\[
E(X) = x_1 \cdot p_1 + x_2 \cdot p_2 + \cdots + x_n \cdot p_n = \sum_{i=1}^{n} x_i \cdot p_i
\]

This means:

- Multiply each possible value \( x_i \) with its probability \( p_i \)
- Add them all up

---

#### 🎲 Example 1: Roll a Fair Die

Each face (1 to 6) has equal probability \( \frac{1}{6} \). What’s the expected value?

\[
E(X) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6}
\]

\[
E(X) = \frac{1 + 2 + 3 + 4 + 5 + 6}{6} = \frac{21}{6} = 3.5
\]

So, the **average outcome** in the long run is **3.5**  
(even though you never roll a 3.5).

---

#### 🎲 Example 2: Coin Toss Game

- **Heads** → Win ₹10  
- **Tails** → Lose ₹5

Let \( X \) be the amount you win.

\[
E(X) = 10 \cdot \frac{1}{2} + (-5) \cdot \frac{1}{2} = \frac{10 - 5}{2} = \frac{5}{2} = 2.5
\]

You earn **₹2.5 on average per toss**, so it’s a **profitable game** in the long run.

---

#### 📈 For Continuous Random Variables

If \( X \) is a continuous variable with probability density function \( f(x) \):

\[
E(X) = \int_{-\infty}^{\infty} x \cdot f(x) \, dx
\]

This is the same idea, but instead of adding, you're integrating over a curve.

---

#### 🔧 Example: Uniform Distribution [0, 1]

Let’s say \( X \sim U(0,1) \)

That means \( f(x) = 1 \) for \( x \in [0, 1] \)

\[
E(X) = \int_0^1 x \cdot 1 \, dx = \int_0^1 x \, dx = \left[ \frac{x^2}{2} \right]_0^1 = \frac{1}{2}
\]

So, the expected value is **0.5** — the midpoint.

---

#### ✨ Interpretation in Real Life

- 📊 **Insurance companies** use it to calculate average payouts.
- 💹 **Economists** use it to find expected returns of investments.
- 🎰 **Gamblers** use it to decide whether a game is worth playing.
- 🤖 **AI/ML models** use it to find average loss (like in loss functions).

## 📌 Properties of Expectation

### 🔢 Linearity

\[
E(aX + b) = aE(X) + b
\]

\[
E(X + Y) = E(X) + E(Y)
\]

✅ *You can pull out constants and split addition.*  
✅ *Even if \(X\) and \(Y\) are dependent!*  

### 🔁 Expectation of a Constant

\[
E(c) = c
\]

✅ *The expectation of a constant is the constant itself.*  

---

### 🧠 Common Misunderstanding

**Expected value is not necessarily the most likely value.**  

Example:  
You might expect to win **₹2.5** on average, but you **never actually get ₹2.5** —  
you either win **₹10** or lose **₹5** in each game.

## 🌟 Why Do We Need Variance and Standard Deviation?

You already know expected value tells us the average outcome. But what if I told you:

- **Two games have the same expected value…**
- **But one is stable, and the other is risky and wild.**

How do we measure how much values vary around the average? That’s where **variance and standard deviation** come in.

They tell us **how spread out or scattered the values of a random variable are** around the expected value.

### 🎯 Intuition

- **Expectation** = Center of the target  
- **Variance/Standard Deviation** = How tightly the arrows are clustered or how far they scatter  

---

## 💡 What Is Variance?

Let’s say a random variable \( X \) has expected value \( E(X) = \mu \).  
Then the variance is:

\[
\text{Var}(X) = E[(X - \mu)^2]
\]

Which means:

1. Take how far each value is from the mean (\( X - \mu \)).
2. Square that difference (so negatives don’t cancel out).
3. Take the **expected value** of that squared difference.
4. This tells you the **average squared deviation from the mean**.

---

### 🧮 Formula (for Discrete Random Variables)

If \( X \) takes values \( x_1, x_2, ..., x_n \) with probabilities \( p_1, p_2, ..., p_n \):

\[
\text{Var}(X) = \sum_{i=1}^{n} (x_i - \mu)^2 \cdot p_i
\]

Also, there’s a **shortcut formula**:

\[
\text{Var}(X) = E(X^2) - [E(X)]^2
\]

We’ll use this a lot—it’s easier to compute!

---

### 🧮 Standard Deviation

**Standard Deviation** is just the **square root of variance**:

\[
\text{SD}(X) = \sqrt{\text{Var}(X)}
\]

So variance is in **squared units**, while standard deviation brings it back to **original units**.

---

## 🎲 Example 1: Roll a Fair Die (1 to 6)

We already found \( E(X) = 3.5 \).

Now let’s calculate the variance:

### Step 1: Compute \( E(X^2) \)

\[
E(X^2) = \frac{1^2 + 2^2 + 3^2 + 4^2 + 5^2 + 6^2}{6} = \frac{1 + 4 + 9 + 16 + 25 + 36}{6} = \frac{91}{6} \approx 15.17
\]

### Step 2: Use the Shortcut Formula

\[
\text{Var}(X) = E(X^2) - [E(X)]^2 = 15.17 - (3.5)^2 = 15.17 - 12.25 = 2.92
\]

### Step 3: Compute Standard Deviation

\[
\text{SD}(X) = \sqrt{2.92} \approx 1.71
\]

This means:  
On average, the values deviate from the mean (3.5) by about **1.71 units**.

---

## 🎯 Interpretation

- **If Variance = 0**, all values are the same (no variation).
- The **larger** the variance/SD, the **more spread out** the values.
- SD is **easier to interpret** than variance since it’s in the same units.

---

## 🧠 Real-Life Use Cases

- 📉 **Finance** → Risk = variance of returns
- 🤖 **Machine Learning** → Variance helps measure how much a model's predictions fluctuate
- ⚡ **Physics** → Measurement errors
- 🏫 **Exams** → SD tells how consistent scores are in a class

### Exampele : Variance and std of Expectation
## 🎯 Expectation = The Center

Expected value tells you **on average**, how much you’ll win or lose.

But **average alone doesn’t tell the whole story**—it doesn’t say how **consistent or risky** the outcomes are.

Let’s compare two different games with the same expected value, but very different spreads.

---

## 🎮 Game A:  
You **always** win ₹10.

- **With probability 1 → ₹10**
- **Expected value:**
  
\[
E(X_A) = 10 \cdot 1 = 10
\]

✅ **No variation. Very stable.**

---

## 🎮 Game B:  
You win ₹0 or ₹20, **each with equal chance**.

| Outcome | Probability |
|---------|------------|
| ₹0      | 0.5        |
| ₹20     | 0.5        |

**Expected value:**

\[
E(X_B) = 0 \cdot 0.5 + 20 \cdot 0.5 = 10
\]

📌 Same expected value: ₹10  
📈 But **Game B is more volatile**.

---

## 🧠 Key Question:  
If both games give ₹10 on average, **which one is more risky?**

- 👉 **Game A is completely stable.**
- 👉 **Game B is risky**—sometimes you get ₹0, sometimes ₹20.

To **measure risk**, we use **variance** and **standard deviation**.

---

## 🧮 Calculating Variance for Each Game:

✅ **Game A (Always ₹10):**  

\[
\text{Var}(X_A) = E[(X - \mu)^2] = (10 - 10)^2 \cdot 1 = 0
\]

\[
\text{Standard Deviation} = \sqrt{0} = 0
\]

✔️ **No variation at all.**

---

✅ **Game B (₹0 or ₹20):**  

\[
\text{Var}(X_B) = (0 - 10)^2 \cdot 0.5 + (20 - 10)^2 \cdot 0.5
\]

\[
= 100 \cdot 0.5 + 100 \cdot 0.5 = 50 + 50 = 100
\]

\[
\text{Standard Deviation} = \sqrt{100} = 10
\]

🎯 **Interpretation:**

- **Game A →** No surprise, **always ₹10 → No risk**
- **Game B →** Big surprises! **Either ₹0 or ₹20 → High risk**

---

## 🎯 Analogy: Archery  
Imagine 5 archers aiming for the bullseye (**value = 10**):

### 🏹 Archer A:  
Every arrow **hits the bullseye perfectly** → scores: **10, 10, 10, 10, 10**

- 🎯 **Average = 10**  
- 📏 **Standard Deviation = 0 → Perfect consistency**

### 🏹 Archer B:  
Sometimes hits 0, sometimes hits 20 → scores: **0, 20, 0, 20, 0**

- 🎯 **Average = 10**  
- 📏 **Standard Deviation = High → Very inconsistent, risky**

---

## 🔑 Final Takeaway

- ✅ **Expectation tells you what you can expect on average.**
- ⚠️ **Variance/Standard Deviation tells you how reliable that average is.**
- 📈 **High standard deviation = high unpredictability or risk.**
- 📉 **Low standard deviation = stable and predictable.**

## 🧠 Expectation of Functions: \( E(X^2), E(X^3), \dots \)

We don’t always want just \( E(X) \). Sometimes, we need:

- **\( E(X^2) \)** → Used in **variance**
- **\( E(X^3), E(X^4) \)** → Used in **skewness** and **kurtosis** (shape of the distribution)
- **\( E(aX + b) \)** → Linear transformation expectation

---

## 🎯 How to Compute \( E(X^2) \)?

If \( X \) has values \( x_1, x_2, ..., x_n \) with probabilities \( p_1, ..., p_n \):

\[
E(X^2) = \sum x_i^2 \cdot p_i
\]

For continuous cases:

\[
E(X^2) = \int x^2 f(x) \,dx
\]

---

## 🔍 Why Do We Care About \( E(X^2), E(X^3), \dots \)?

- **\( E(X^2) \)** → Needed to calculate variance:

\[
\text{Var}(X) = E(X^2) - [E(X)]^2
\]

- **\( E(X^3) \)** → Measures **skewness** (is the distribution leaning left or right?)
- **\( E(X^4) \)** → Measures **kurtosis** (how heavy the tails are)
- **In physics:** \( E(X^2) \) gives **moment of inertia**
- **In ML/Stats:** Used for **moment-generating functions**, feature engineering, etc.

---

## 🔢 Mini Example

Let \( X \) be a random variable with values **1, 2, 3** and probabilities **0.2, 0.5, 0.3**.

### Step 1: Compute \( E(X) \)

\[
E(X) = 1 \cdot 0.2 + 2 \cdot 0.5 + 3 \cdot 0.3 = 2.1
\]

### Step 2: Compute \( E(X^2) \)

\[
E(X^2) = 1^2 \cdot 0.2 + 2^2 \cdot 0.5 + 3^2 \cdot 0.3
\]

\[
= 0.2 + 2.0 + 2.7 = 4.9
\]

### Step 3: Compute Variance

\[
\text{Var}(X) = E(X^2) - [E(X)]^2
\]

\[
= 4.9 - (2.1)^2 = 4.9 - 4.41 = 0.49
\]

---
