# Probability Distributions

## Random Variable
A random variable is a numerical value determined by the outcome of a random phenomenon or experiment. It's a way to quantify randomness. In other words, it represents possible outcomes of an experiment and assigns numerical values to these outcomes.

**Example:**
Imagine you roll a six-sided dice. The outcome of the roll (which can be 1, 2, 3, 4, 5, or 6) is a random variable because the result is determined by chance.

If we call this random variable \( X \), then:
- \( X \) can take the value 1 if you roll a 1.
- \( X \) can take the value 2 if you roll a 2.
- And so on, until \( X \) can take the value 6 if you roll a 6.

### Algebraic Variable
An algebraic variable, on the other hand, is a symbol used to represent a number in mathematical expressions and equations. The value of an algebraic variable is typically unknown until you solve the equation or expression.

**Example:**
Consider the equation \( y = 3x + 2 \). Here, \( x \) and \( y \) are algebraic variables:
- \( x \) can represent any real number.
- Once you know the value of \( x \), you can calculate the value of \( y \).

### Key Differences
1. **Deterministic vs. Random:** 
   - **Random Variable:** The value is determined by a random process.
   - **Algebraic Variable:** The value is typically unknown but is determined by solving an equation or expression.

2. **Context of Use:**
   - **Random Variable:** Often used in probability and statistics.
   - **Algebraic Variable:** Used in algebra, calculus, and other areas of mathematics.

## What is Probability Distributions ?

A **Probability Distribution** is a list of all possible outcomes of a random variable, along with their corresponding probability values.

For example, if we consider a coin toss, this experiment is random, and we can define a random variable, say *X*, as:  
*X = {1 (H), 0 (T)}*  
where 1 represents heads and 0 represents tails. Now, if we assign corresponding probability values to the possible outcomes of the random variable (H and T in this case), it is called a probability distribution.

| Coin Toss      | 1 (H) | 0 (T) |
|----------------|-------|-------|
| Probabilities  | 1/2   | 1/2   |

### üé≤ Flipping Two Dice Example

Let‚Äôs consider the example of flipping two dice at the same time. We want to sum their outcomes and assign a corresponding probability function. The random variable becomes:

- For **Dice 1**, \( X_1 = \{1, 2, 3, 4, 5, 6\} \)
- For **Dice 2**, \( X_2 = \{1, 2, 3, 4, 5, 6\} \)

---

### üßÆ Sum of Outcomes Table

| **Dice Roll (Dice 1)** | **1** | **2** | **3** | **4** | **5** | **6** |
|------------------------|-------|-------|-------|-------|-------|-------|
| **Dice 2 ‚Üí**           |       |       |       |       |       |       |
| **1**                  | 2     | 3     | 4     | 5     | 6     | 7     |
| **2**                  | 3     | 4     | 5     | 6     | 7     | 8     |
| **3**                  | 4     | 5     | 6     | 7     | 8     | 9     |
| **4**                  | 5     | 6     | 7     | 8     | 9     | 10    |
| **5**                  | 6     | 7     | 8     | 9     | 10    | 11    |
| **6**                  | 7     | 8     | 9     | 10    | 11    | 12    |

---

### üìä Frequency and Probability Table

Total number of outcomes = \( 6 x 6 = 36 \)

| **Sum (Outcomes)** | **Combinations**                               | **Frequency** | **Probability** |
|--------------------|------------------------------------------------|---------------|------------------|
| 2                  | (1,1)                                          | 1             | 1/36             |
| 3                  | (1,2), (2,1)                                    | 2             | 2/36             |
| 4                  | (1,3), (2,2), (3,1)                             | 3             | 3/36             |
| 5                  | (1,4), (2,3), (3,2), (4,1)                      | 4             | 4/36             |
| 6                  | (1,5), (2,4), (3,3), (4,2), (5,1)               | 5             | 5/36             |
| 7                  | (1,6), (2,5), (3,4), (4,3), (5,2), (6,1)        | 6             | 6/36             |
| 8                  | (2,6), (3,5), (4,4), (5,3), (6,2)               | 5             | 5/36             |
| 9                  | (3,6), (4,5), (5,4), (6,3)                      | 4             | 4/36             |
| 10                 | (4,6), (5,5), (6,4)                             | 3             | 3/36             |
| 11                 | (5,6), (6,5)                                    | 2             | 2/36             |
| 12                 | (6,6)                                          | 1             | 1/36             |

---

### üìê Probability Function \( P(X = x) \)

$$
P(X = x) =
\begin{cases}
\frac{1}{36} & \text{if } x = 2 \text{ or } x = 12 \\
\frac{2}{36} & \text{if } x = 3 \text{ or } x = 11 \\
\frac{3}{36} & \text{if } x = 4 \text{ or } x = 10 \\
\frac{4}{36} & \text{if } x = 5 \text{ or } x = 9 \\
\frac{5}{36} & \text{if } x = 6 \text{ or } x = 8 \\
\frac{6}{36} & \text{if } x = 7 \\
0 & \text{otherwise}
\end{cases}
$$
![Dice Sum Distribution Visualization](../images/dice_example.png)  

[Code Example (Jupyter Notebook)](../notebooks/03.%20Probability%20Distribution%20Functions.ipynb)  


### What if we have 100 dice for the experiment?

If we were to toss **100 dice** in the experiment, creating a table to represent all possible outcomes would be impractical due to the sheer number of combinations. In real-world scenarios, the number of outcomes can be significantly larger, making the creation of such tables tedious and inefficient.

---

### **Solution**

Instead of writing a distribution table, we could use a **mathematical function** to model the relationship between outcomes and their corresponding probabilities. This approach simplifies the representation and provides additional benefits.

#### **Benefits of a Mathematical Model**
- Produces outputs/probabilities for all values without requiring a physical table.
- Can be visualized using graphs, showing the shape of the probability distribution.

Such functions are known as **Probability Distribution Functions**, commonly referred to as **Probability Distributions**.

---

This solution allows us to handle complex scenarios more effectively while gaining deeper insights through graphical and mathematical representations.

### Types of Probability Distribution Functions (PDF)

Probability Distribution Functions (PDFs) can be broadly divided into two major types:

---

### 1. **Discrete Probability Distribution**
A discrete probability distribution applies to scenarios where the random variable can take on a countable number of distinct values. The probability of each outcome is explicitly defined, and the total sum of probabilities equals 1.

#### Examples:
- **Bernoulli Distribution**: Represents a single trial with two possible outcomes, such as success (1) and failure (0).
- **Binomial Distribution**: Models the number of successes in a fixed number of independent trials, such as flipping a coin multiple times.
- **Poisson Distribution**: Describes the probability of a number of events occurring in a fixed interval of time or space, such as the number of calls a call center receives in an hour.

---

### 2. **Continuous Probability Distribution**
A continuous probability distribution is used when the random variable can take on an infinite number of possible values within a range. These are represented by probability density functions, and the probability of a specific value is zero (but ranges have probabilities).

#### Examples:
- **Normal Distribution (Gaussian)**: A symmetric, bell-shaped curve that models many natural phenomena like heights, weights, or test scores.
- **Exponential Distribution**: Models the time between events in a Poisson process, such as the lifespan of a device.
- **Uniform Distribution**: All values within a given range are equally likely, such as random numbers between 0 and 1.

---

### Importance of Probability Distributions

- **Provides Insights into Data Shape:** Probability distributions give us an understanding of the shape or distribution of the data, which helps in identifying patterns, trends, and central tendencies.
  
- **Leverages Famous Distributions:** If our data follows a well-known probability distribution, we gain significant insights about the data automatically. For instance:
  - We can predict certain outcomes.
  - We can apply known statistical methods and properties directly.

Probability distributions are fundamental tools for analyzing and interpreting data effectively in numerous fields, from science to business decision-making.

### üá≥üáµ vs üá∫üá∏ Salary Distribution: Real-World Example of Probability Distributions

### üéØ Goal: Understand how probability distributions help analyze data

Let‚Äôs compare monthly salary distributions in Nepal and the United States to understand how different data patterns emerge and how distributions help us.

---

### üîç Hypothetical Data Assumption

| **Country** | **Avg Monthly Salary (USD)** | **Distribution Type**     | **Description**                                                                 |
|-------------|------------------------------|---------------------------|---------------------------------------------------------------------------------|
| Nepal       | $300                         | Right-skewed (Log-Normal) | Most people earn below the average; a few earn much higher.                    |
| USA         | $4,500                       | Normal (Bell Curve)       | Salaries are more symmetrically distributed around the mean.                   |


![NP vs US salary](../images/npvsus.png)  

### ‚úÖ Interpretation:

- **Nepal (Log-Normal):**  
  The distribution is skewed to the right. Most people earn between $100‚Äì$500, but a few earn more than $1000.

- **USA (Normal):**  
  The distribution is centered around $4500. Most people earn near the average, with fewer people earning extremely low or extremely high amounts.


[Code Example (Jupyter Notebook)](../notebooks/03.%20Probability%20Distribution%20Functions.ipynb)  

### A Note on Parameters

Parameters in probability distributions are numerical values that determine the **shape**, **location**, and **scale** of the distribution.

Different probability distributions have unique sets of parameters that define their shape and characteristics. Understanding these parameters is essential for **statistical analysis** and **inference**, as they provide deeper insights into the data and its behavior.


## Probability Distributions Functions
A probability Distribution Function (PDF) is a mathematical function that describes the probability of obtaining different values of a random variable in a particular probability distribution.

### Types of Probability Distribution Functions

Probability Distribution Functions can be divided into two main types:  
- **Probability Mass Function (PMF):**  
  The function that represents the probability distribution for discrete random variables.

- **Probability Density Function (PDF):**  
  The function that represents the probability distribution for continuous random variables.

---

### **Cumulative Distribution Function (CDF):**  
The CDF is a probability distribution function that can be derived from the above two distribution functions, PMF and PDF.



